# Парсер данных с веб-страницы

### Описание:
* Необходимо написать программу для парсинга данных с веб-страницы, используя библиотеку BeautifulSoup или другую библиотеку для парсинга HTML. Страница содержит список книг с их названиями, авторами и ценами. Эти данные нужно извлечь и сохранить в CSV-файл.

### Техническое задание:
* Входные данные: URL страницы (например, страница интернет-магазина с книгами).

* Программа должна:
  * Загрузить HTML-страницу с указанного [URL](https://www.ozon.ru/category/knigi-16500/?category_was_predicted=true&deny_category_prediction=true&from_global=true&text=python) (для упрощения данная страница, на момент сохранения представлена в файле `python.html`,
настоятельно рекомендуется работать с данным файлом, а затем проверить уже по URL). 
  * Извлечь список книг с их названиями, авторами и ценами.
  * Сохранить данные в формате CSV с заголовками "Название", "Автор", "Цена".

* Библиотеки для работы: 
  * requests, 
  * [BeautifulSoup](https://habr.com/ru/articles/544828/), 
  * csv.

* Дополнительно:
  * Обработать возможные ошибки при подключении к сайту.
  * Программа должна быть устойчивой к изменению структуры страницы.

### Что значит "программа должна быть устойчивой к изменению структуры страницы"?

Когда говорится, что программа должна быть устойчивой к изменению структуры страницы, это означает, что программа должна 
уметь корректно извлекать данные даже при незначительных изменениях в HTML-разметке веб-страницы. 
Структура страницы может меняться, например, если разработчики сайта добавят новые элементы, изменят классы CSS, изменят расположение блоков и т.д.

Чтобы обеспечить такую устойчивость, следует придерживаться следующих практик:

1. Извлечение данных по уникальным атрибутам:
* Вместо того, чтобы полагаться на точное местоположение элементов в HTML (например, фиксированные теги или иерархию DOM), лучше использовать уникальные идентификаторы, классы или другие атрибуты для поиска нужных данных.
* Например, если у блока с книгой есть уникальный класс book-item, стоит ориентироваться на него при извлечении данных.

```python
# Пример: выбираем блоки с книгами по классу
books = soup.find_all("div", class_="book-item")
```
Если структура страницы изменится (например, элементы переместятся), но класс останется прежним, программа продолжит работать корректно.

2. Обработка нескольких возможных структур:

* Программа может быть настроена так, чтобы обрабатывать несколько возможных вариантов структуры страницы.
* Например, если цены книг могут находиться в разных тегах (span или div), можно добавить проверку обоих случаев:

```python
# Пример: цена может находиться в разных тегах
price = book.find("span", class_="price") or book.find("div", class_="price")
```

3. Использование регулярных выражений:

* Иногда классы или идентификаторы могут изменяться с добавлением дополнительных символов или версий. Для поиска таких элементов можно использовать регулярные выражения.

```python
# Пример: поиск элементов с классом, содержащим "price"
price = book.find("span", class_=re.compile(r"price"))
```

4. Добавление резервного плана (fallback):

* Если определённый элемент не найден (например, класс был изменён или элемент временно отсутствует), программа должна корректно продолжить работу, сохранив частичные данные или пропустив отсутствующие элементы. 
Это предотвращает полное падение программы при небольших изменениях.

```python
# Пример: обработка отсутствующих данных
author = book.find("span", class_="author")
if author:
    author_name = author.text
else:
    author_name = "Неизвестен"
```

5. Логирование и обработка исключений:

* Важно добавлять логирование и обработку исключений, чтобы при возникновении ошибки в процессе парсинга (например, если изменился важный элемент страницы) программа не завершалась, а сообщала об ошибке и продолжала работу для других элементов.

```python
# Пример: обработка исключений
try:
    price = book.find("span", class_="price").text
except AttributeError:
    price = "Не указана"
```


### Пример устойчивого парсера:

```python
import requests
from bs4 import BeautifulSoup
import csv

url = "https://example.com/books"
response = requests.get(url)
soup = BeautifulSoup(response.content, 'html.parser')

# Открываем CSV файл для записи
with open('books.csv', mode='w', newline='', encoding='utf-8') as file:
    writer = csv.writer(file)
    writer.writerow(["Название", "Автор", "Цена"])

    books = soup.find_all("div", class_="book-item")
    for book in books:
        title = book.find("h2", class_="book-title").text
        
        # Используем безопасные извлечения с fallback
        author = book.find("span", class_="book-author")
        author_name = author.text if author else "Неизвестен"
        
        # Работаем с изменениями структуры
        price = book.find("span", class_="book-price") or book.find("div", class_="book-price")
        price_value = price.text if price else "Не указана"

        writer.writerow([title, author_name, price_value])
```
